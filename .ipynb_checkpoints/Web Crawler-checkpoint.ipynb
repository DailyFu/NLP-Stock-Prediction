{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, SoupStrainer, BeautifulStoneSoup\n",
    "import datetime\n",
    "import unicodedata\n",
    "import requests\n",
    "import pandas as pd\n",
    "import quandl\n",
    "import config\n",
    "import dateutil.relativedelta\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S&P 500 index data downloaded from Yahoo Finance GSPC\n",
    "gspc_df = pd.read_csv(\"Data/gspc.csv\",parse_dates=['Date'],index_col=\"Date\")\n",
    "\n",
    "def get_index_price(input_date,market_open):\n",
    "    if market_open == True:\n",
    "        price = gspc_df.loc[gspc_df.index==np.datetime64(input_date.date()),\"Open\"]  \n",
    "    else:\n",
    "        price = gspc_df.loc[gspc_df.index==np.datetime64(input_date.date()),\"Adj Close\"] \n",
    "        \n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns Dataframe of document links for a given CIK\n",
    "def get_sec_docs(cik=\"0001065088\"):\n",
    "    base_url = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "    inputted_cik = cik\n",
    "    payload = {\n",
    "        \"action\" : \"getcompany\",\n",
    "        \"CIK\" : inputted_cik,\n",
    "        \"type\" : \"8-K\",\n",
    "        \"output\":\"xml\"\n",
    "        #\"dateb\" : \"20180331\",\n",
    "        #\"count\" : \"100\",\n",
    "        #\"owner\" : \"include\"\n",
    "    }\n",
    "    sec_response = requests.get(url=base_url,params=payload)\n",
    "    soup = BeautifulSoup(sec_response.text,'lxml')\n",
    "    url_list = soup.findAll('filinghref')\n",
    "    html_list = []\n",
    "    # Get html version of links\n",
    "    for link in url_list:\n",
    "        link = link.string\n",
    "        if link.split(\".\")[len(link.split(\".\"))-1] == 'htm':\n",
    "            txtlink = link + \"l\"\n",
    "            html_list.append(txtlink)\n",
    "\n",
    "    doc_list = []\n",
    "    doc_name_list = []\n",
    "    # Get links for txt versions of files\n",
    "    for k in range(len(html_list)):\n",
    "        txt_doc = html_list[k].replace(\"-index.html\",\".txt\")\n",
    "        doc_name = txt_doc.split(\"/\")[-1]\n",
    "        doc_list.append(txt_doc)\n",
    "        doc_name_list.append(doc_name)\n",
    "        # Create dataframe of CIK, doc name, and txt link\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "        \"cik\" : [cik]*len(html_list),\n",
    "        \"txt_link\" : doc_list,\n",
    "        \"doc_name\": doc_name_list\n",
    "        }\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts text and submission datetime from document link\n",
    "def extract_text(link):\n",
    "    r = requests.get(link)\n",
    "    #Parse 8-K document\n",
    "    filing = BeautifulSoup(r.content,\"html.parser\",from_encoding=\"ascii\")\n",
    "    #Extract datetime\n",
    "    submission_dt = filing.find(\"acceptance-datetime\").string[:14]\n",
    "    #Extract HTML sections\n",
    "    submission_dt = datetime.datetime.strptime(submission_dt,\"%Y%m%d%H%M%S\")\n",
    "    for section in filing.findAll(\"html\"):\n",
    "        #Remove tables\n",
    "        for table in section(\"table\"):\n",
    "            table.decompose()\n",
    "        #Convert to unicode\n",
    "        section = unicodedata.normalize(\"NFKD\",section.text)\n",
    "        section = section.replace(\"\\t\",\" \").replace(\"\\n\",\" \").replace(\"/s\",\" \").replace(\"\\'\",\"'\")\n",
    "    filing = \"\".join((section))\n",
    "    \n",
    "    return filing, submission_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authenticate with API KEY\n",
    "quandl.ApiConfig.api_key = config.api_key # YOUR API KEY HERE\n",
    "\n",
    "def get_quandl_data(ticker,end_date,market_open):\n",
    "    if market_open == True:\n",
    "        quandl_param = \"WIKI/\" + ticker + \".8\"  \n",
    "    else:\n",
    "        quandl_param = \"WIKI/\" + ticker + \".11\" \n",
    "   \n",
    "    end_date = datetime.datetime.strftime(end_date,\"%Y-%m-%d\") \n",
    "    price = quandl.get(quandl_param,start_date=end_date,end_date=end_date).values[0,0]\n",
    "    return price\n",
    "\n",
    "def get_movement(ticker,start_date,release_date):\n",
    "    market_close = release_date.replace(hour=16,minute=0,second=0)\n",
    "    market_open = release_date.replace(hour=9,minute=30,second=0)\n",
    "    \n",
    "    # If report is released after market hours, change of close and next day open\n",
    "    if release_date > market_close:\n",
    "        start_date = release_date\n",
    "        end_date = release_date + datetime.timedelta(days=1)\n",
    "        end_date = weekday_check(end_date)\n",
    "        price_before_release = get_quandl_data(ticker,start_date,market_open=False)\n",
    "        price_after_release = get_quandl_data(ticker,end_date,market_open=True)\n",
    "        \n",
    "        index_before_release = get_index_price(start_date,market_open=False)\n",
    "        index_after_release = get_index_price(end_date,market_open=True)\n",
    "        \n",
    "    # If report is released before market hours, take change of yesterday's close and today's open\n",
    "    elif end_date < market_open:\n",
    "        start_date = release_date - datetime.timedelta(days=1)\n",
    "        start_date = weekday_check(start_date)\n",
    "        end_date = release_date\n",
    "        \n",
    "        price_before_release = get_quandl_data(ticker,start_date,market_open=False)\n",
    "        price_after_release = get_quandl_data(ticker,end_date,market_open=True) \n",
    "        \n",
    "        index_before_release = get_index_price(start_date,market_open=False)\n",
    "        index_after_release = get_index_price(end_date,market_open=True)\n",
    "        \n",
    "    else:\n",
    "        start_date = release_date - datetime.timedelta(days=1)\n",
    "        end_date = release_date\n",
    "        price_before_release = get_quandl_data(ticker,start_date,market_open=False)\n",
    "        price_after_release = get_quandl_data(ticker,end_date,market_open=False)\n",
    "        \n",
    "        index_before_release = get_index_price(start_date,market_open=False)\n",
    "        index_after_release = get_index_price(end_date,market_open=False)\n",
    "        \n",
    "    price_pct_change = calculate_pct_change(price_after_release,price_before_release)\n",
    "    index_pct_change = calculate_pct_change(index_after_release,index_before_release)\n",
    "def get_recent_movements(ticker,end_date):\n",
    "    end_date = datetime.datetime.strftime(end_date,\"%Y-%m-%d\")\n",
    "    quandl_param = \"WIKI/\" + ticker + \".11\"\n",
    "    close_price = quandl.get(quandl_param,start_date=end_date,end_date=end_date).values[0,0]\n",
    "    return close_price\n",
    "\n",
    "def calculate_pct_change(end_value,start_value):\n",
    "    pct_change = (end_value - start_value) / start_value\n",
    "    pct_change = round(pct_change,4)\n",
    "    return pct_change\n",
    "\n",
    "def weekday_check(date):\n",
    "    # If date is Saturday or Sunday, reset date to the preceding Friday\n",
    "    if date.isoweekday() == 6:\n",
    "        date = date + datetime.timedelta(days=-1)\n",
    "    elif date.isoweekday() == 7:\n",
    "        date = date + datetime.timedelta(days=-2)\n",
    "    return date\n",
    "\n",
    "def get_closing_price(ticker=\"EBAY\",release_date=dt):\n",
    "    #Setup variables\n",
    "    previous_closes = dict()\n",
    "   \n",
    "    #1 Week\n",
    "    previous_closes[\"week_before\"] = release_date + datetime.timedelta(weeks=-1)\n",
    "    #1 Month\n",
    "    previous_closes[\"month_before\"] = release_date + dateutil.relativedelta.relativedelta(months=-1)\n",
    "    #1 Quarter\n",
    "    previous_closes[\"quarter_before\"] = release_date + dateutil.relativedelta.relativedelta(months=-3)\n",
    "    #1 Year\n",
    "    previous_closes[\"year_before\"] = release_date +  dateutil.relativedelta.relativedelta(years=-1)\n",
    "    \n",
    "    #Check if date falls on a weekend\n",
    "    release_date = weekday_check(release_date)\n",
    "\n",
    "    #Get close price from Quandl\n",
    "    end_date_price = get_quandl_data(ticker,release_date,market_open=False)\n",
    "    \n",
    "    #Check if date falls on a weekend and get closing price\n",
    "    for date in previous_closes.keys():\n",
    "        previous_closes[date] = weekday_check(previous_closes[date])     \n",
    "        #Get closing prices\n",
    "        previous_closes[date] = get_quandl_data(ticker,previous_closes[date],market_open=False)\n",
    "    return previous_closes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebay_df = get_sec_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus, dt = extract_text(ebay_df['txt_link'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'month_before': 37.74,\n",
       " 'quarter_before': 37.64,\n",
       " 'week_before': 39.82,\n",
       " 'year_before': 31.83}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closing_price()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
